Introduction
===========================================================================
The question was [asked][1] on the GHC mail list whether we could change the
function `f` with the call site g:

    f :: Int -> Int -> Int -> Int -> Int
    f !i !j !s !m
     | i == 0    = s+m
     | otherwise = f (i-1) (j-1) (s + i+1) (m + j*5)

     g :: Int -> Int
     g !k = f k k 0 0

into the function `ff` with call site `gg`:

    ff :: Int -> Int -> Int -> Int
    ff !i !s !m
     | i == 0    = s+m
     | otherwise = ff (i-1) (s + i+1) (m + i*5)

    gg :: Int -> Int
    gg !k = ff k 0 0

The idea was that we could replace the j references with i, since i and j are
equal throughout the loop. It was suggested that this transformation would
help code generated by stream fusion transformation. 

It is possible to get LLVM to do this transformation through a combination of
tail-call elimination, inlining, induction variable optimization, and global
value numbering. This works fine on x86_64 where we can pass parameters in
registers, but fails to fully fire in i386 back end because LLVM gets caught
up by aliasing problems because all function parameters are passed on the
stack.

In this article I will explore how Haskell loops get manifest and optimized in
the GHC back ends. This article contains a lot of cmm and llvm bitcode. I
assume some knowledge of GHC's execution model and how it generates the
low-level cmm code. There is a wonderful explanation GHC's code generation of
cmm code in the [GHC commentary][2] written by Max Bolingbroke. 

The cmm and llvm code I show in this article was generated with GHC 7.0 and
LLVM 2.8.

The Power of LLVM
===========================================================================

LLVM does a great job of optimizing the loops it can see. If we translate the
`f` function to a simple loop in C we would get something like this:

    fWorker(int i, int j, int s, int m) {
      loop:
        if(i == 0) goto end;
        s = s + i + 1;
        m = m + j * 5;
        i = i - 1;
        j = j - 1;
        goto loop;
      end:
        return s + m;
    }

    g(int k) {
      return fWorker(k,k,0,0);
    }

Running `opt -mem2reg -inline -indvars -loop-deletion` on the LLVM bitcode, we
get the following output.

    define i32 @g(i32 %k) nounwind ssp {
    entry:
      %"alloca point" = bitcast i32 0 to i32          ; <i32> [#uses=0]
      %tmp.i = add i32 %k, 1                          ; <i32> [#uses=1]
      %tmp1.i = mul i32 %k, %tmp.i                    ; <i32> [#uses=1]
      %tmp3.i = zext i32 %k to i33                    ; <i33> [#uses=1]
      %tmp4.i = add i32 %k, -1                        ; <i32> [#uses=1]
      %tmp5.i = zext i32 %tmp4.i to i33               ; <i33> [#uses=1]
      %tmp6.i = mul i33 %tmp3.i, %tmp5.i              ; <i33> [#uses=1]
      %tmp7.i = lshr i33 %tmp6.i, 1                   ; <i33> [#uses=1]
      %tmp8.i = trunc i33 %tmp7.i to i32              ; <i32> [#uses=2]
      %tmp10.i = mul i32 %k, %k                       ; <i32> [#uses=1]
      %tmp11.i = mul i32 %tmp10.i, 5                  ; <i32> [#uses=1]
      %tmp13.i = mul i32 %tmp8.i, 5                   ; <i32> [#uses=1]
      %tmp2.i = add i32 0, %tmp1.i                    ; <i32> [#uses=1]
      %tmp9.i = sub i32 %tmp2.i, %tmp8.i              ; <i32> [#uses=1]
      %tmp12.i = add i32 0, %tmp11.i                  ; <i32> [#uses=1]
      %tmp14.i = sub i32 %tmp12.i, %tmp13.i           ; <i32> [#uses=1]
      %0 = add nsw i32 %tmp9.i, %tmp14.i              ; <i32> [#uses=1]
      br label %return

    return:                                           ; preds = %entry
      ret i32 %0
    }

We see that the `fWorker` function was inlined into the body of `g`. LLVM was
also able to transform the loop into a simple calculation since all the loop
does is some computation based on induction variables. Also, we see that the
variable `%k` takes the place of both `i` and `j` in the original loop, which
accomplishes the original goal: `g` has been transformed into an *optimized*
version of `gg`.

If we can translate the original Haskell function `f` into something that
looks like our C loop, we can be confident that LLVM will do a good job
optimizing it.

Haskell Loops
===========================================================================

GHC does a [worker/wrapper transformation][3] on the function `f` which produces
the following worker function:

    F.$wf =
      \ (ww_smi :: GHC.Prim.Int#)
        (ww1_smm :: GHC.Prim.Int#)
        (ww2_smq :: GHC.Prim.Int#)
        (ww3_smu :: GHC.Prim.Int#) ->
        case ww_smi of wild_B1 {
          __DEFAULT ->
            F.$wf
              (GHC.Prim.-# wild_B1 1)
              (GHC.Prim.-# ww1_smm 1)
              (GHC.Prim.+# (GHC.Prim.+# ww2_smq wild_B1) 1)
              (GHC.Prim.+# ww3_smu (GHC.Prim.*# ww1_smm 5));
          0 -> GHC.Prim.+# ww2_smq ww3_smu
        }

The function `g` first evaluates the `k` parameter that was passed to it then
calls the worker function (`$wf`) directly from `g`. Note that GHC can not
inline the worker function here because it is a recursive function.

    F.g =
      \ (k_ag4 :: GHC.Types.Int) ->
        case k_ag4 of _ { GHC.Types.I# ww_smi ->
        case F.$wf ww_smi ww_smi 0 0 of ww1_smy { __DEFAULT ->
        GHC.Types.I# ww1_smy
        }
        }
        
When `g` gets lowered to cmm, it is broken into three pieces: 

1. Entry to the function `g`
2. The return from the first case (after evaluating the parameter `k`)
3. The return from the second case (after the `$wf` function)

Entry to `g`
---------------------------------------------------------------------------
    F.g_entry()
        cOF:
            if (Sp - 16 < I32[BaseReg + 84]) goto cOH;
            R1 = I32[Sp + 0];
            I32[Sp + 0] = spc_info;
            if (R1 & 3 != 0) goto cOK;
            jump I32[R1] ();
        cOH:
            R1 = F.g_closure;
            jump (I32[BaseReg - 4]) ();
        cOK: jump spc_info ();


The entry to the `g` function is pretty straight forward. It first does a
stack check to make sure it has enough room to call `$wf` (16 bytes are
required for the 4 parameters). Next it loads `k` into `R1` and pushes the
return address `spc_info` onto the stack. It checks the tag bits on `k`
(stored in `R1`) to see if it is already evaluated and either jumps to it to
evaluate it or jumps directly to the continuation (`spc_info`).

The return from evaluating `k` is handled in the `spc_info` function.


Return from the first case (evaluating the parameter `k`)
---------------------------------------------------------------------------
    spc_ret()
        cNL:
            I32[Sp - 4] = 0;
            I32[Sp - 8] = 0;
            I32[Sp - 12] = I32[R1 + 3];
            I32[Sp - 16] = I32[R1 + 3];
            I32[Sp + 0] = soi_info;
            Sp = Sp - 16;
            jump F.$wf_info ();
            
On entry to the `spc_ret` function, we know that `k` is evaluated and stored
in `R1`. The `spc_ret` function pushes the return address (`soi_info`) and all
of the arguments for the `$wf` function onto the stack and then calls the
`$wf` function.

Remember that `k` is a boxed integer, so `R1` points to a heap allocated chunk
8 bytes long that contains the `I#` tag in the first word and the primitive
integer in the second word. `R1` is tagged as evaluated on entry to `spc_ret`
which means that the lowest bit is already set to one. To get to the the
primitive int, we need to move over three more bytes which is why we see the
load of [R1 + 3].

Once all the parameters are on the stack, we call the `$wf` function.

The Loop (`$wf` function)
---------------------------------------------------------------------------
    F.$wf_entry()
    cC1:
        _snG::I32 = I32[Sp + 0];
        if (_snG::I32 != 0) goto cC5;
        _cC9::I32 = I32[Sp + 8] + I32[Sp + 12];
        R1 = _cC9::I32;
        Sp = Sp + 16;
        jump (I32[Sp + 0]) ();
    cC5:
        _soT::I32 = I32[Sp + 4] * 5;
        _soO::I32 = I32[Sp + 12] + _soT::I32;
        _soS::I32 = I32[Sp + 8] + _snG::I32;
        _soR::I32 = _soS::I32 + 1;
        _soQ::I32 = I32[Sp + 4] - 1;
        _soP::I32 = _snG::I32 - 1;
        I32[Sp + 12] = _soO::I32;
        I32[Sp + 8] = _soR::I32;
        I32[Sp + 4] = _soQ::I32;
        I32[Sp + 0] = _soP::I32;
        jump F.$wf_info ();

The `$wf` function is compiled to something that looks quite a bit like a
loop. On entry to `$wf`, the stack looks as follows (stack grows down):

          -----------
          |soi_info|
          ----------
          |   m    |
          ----------
          |   s    |
          ----------
          |   j    |
    Sp -> ----------
          |   i    |
          ----------

We check to see if the loop should end (`i == 0`) and if so we load the return
value into `R1`, pop the arguments from the stack and jump to the return
address. The main body of the loop computes the updates to the parameters,
stores them back onto the stack, and jumps back to the top of the function.


Return from the second case (the `$wf` function)
---------------------------------------------------------------------------
    soi_ret()
        cMk:
            Hp = Hp + 8;
            if (Hp > I32[BaseReg + 92]) goto cMq;
            I32[Hp - 4] = GHC.Types.I#_con_info;
            I32[Hp + 0] = R1;
            R1 = Hp - 3;
            Sp = Sp + 4;
            jump (I32[Sp + 0]) ();
        cMr: jump stg_gc_unbx_r1 ();
        cMq:
            I32[BaseReg + 112] = 8;
            goto cMr;

After returning from `$wf` we need to box the primitive integer (returned to
us from `$wf` in `R1`) and jump to the return address on top of the stack. We
box the int by allocating 8 bytes in the heap and storing the `I#` tag and the
primitive int in our freshly allocated space. Next, The `k` value that was
passed to `g` is then popped from the stack (`Sp = Sp + 4`). Finally, we jump
to the return address on top of the stack that contains the continuation for
`g`.

Translation to LLVM
===========================================================================
Now let's take a look at how the `$wf` gets translated into LLVM bitcode. In
particular, we will take a look at the LLVM translation of the `F.$wf_entry()`
and `spc_ret()` cmm functions.

Translation of `$wf`
---------------------------------------------------------------------------
After translating to LLVM, we run `opt -O1` and get the following LLVM code:

    define cc10 void @F_zdwf_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cDh:
      %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
      %lnDn2 = icmp eq i32 %lnDl1, 0                  ; <i1> [#uses=1]
      br i1 %lnDn2, label %nDq, label %tailrecurse.nDq_crit_edge

    tailrecurse.nDq_crit_edge:                        ; preds = %cDh
      %lnDP = getelementptr inbounds i32* %Sp_Arg, i32 1 ; <i32*> [#uses=2]
      %lnDU = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=2]
      %lnE0 = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=2]
      %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
      %tmp7 = add i32 %lnDl1, -1                      ; <i32> [#uses=2]
      %tmp8 = zext i32 %tmp7 to i33                   ; <i33> [#uses=1]
      %tmp9 = add i32 %lnDl1, -2                      ; <i32> [#uses=1]
      %tmp10 = zext i32 %tmp9 to i33                  ; <i33> [#uses=1]
      %tmp11 = mul i33 %tmp8, %tmp10                  ; <i33> [#uses=1]
      %tmp12 = lshr i33 %tmp11, 1                     ; <i33> [#uses=1]
      %tmp13 = trunc i33 %tmp12 to i32                ; <i32> [#uses=2]
      %tmp15 = mul i32 %lnDP.promoted, 5              ; <i32> [#uses=2]
      %tmp16 = add i32 %tmp15, -5                     ; <i32> [#uses=1]
      %tmp17 = mul i32 %tmp7, %tmp16                  ; <i32> [#uses=1]
      %tmp4 = mul i32 %lnDl1, %lnDl1                  ; <i32> [#uses=1]
      %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
      %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]
      %tmp20 = mul i32 %tmp13, 5                      ; <i32> [#uses=1]
      %tmp18 = add i32 %lnDU.promoted, %tmp17         ; <i32> [#uses=1]
      %tmp5 = add i32 %lnE0.promoted, %tmp4           ; <i32> [#uses=1]
      %tmp = sub i32 %lnDP.promoted, %lnDl1           ; <i32> [#uses=1]
      %tmp6 = add i32 %tmp5, 1                        ; <i32> [#uses=1]
      %tmp14 = sub i32 %tmp6, %tmp13                  ; <i32> [#uses=1]
      %tmp19 = add i32 %tmp18, %tmp15                 ; <i32> [#uses=1]
      %tmp21 = sub i32 %tmp19, %tmp20                 ; <i32> [#uses=1]
      store i32 %tmp, i32* %lnDP
      store i32 %tmp21, i32* %lnDU
      store i32 %tmp14, i32* %lnE0
      store i32 0, i32* %Sp_Arg
      br label %nDq

    nDq:                                              ; preds = %tailrecurse.nDq_crit_edge, %cDh
      %lnDs = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=1]
      %lnDu = load i32* %lnDs                         ; <i32> [#uses=1]
      %lnDw = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=1]
      %lnDy = load i32* %lnDw                         ; <i32> [#uses=1]
      %lnDz = add i32 %lnDy, %lnDu                    ; <i32> [#uses=1]
      %lnDC = getelementptr inbounds i32* %Sp_Arg, i32 4 ; <i32*> [#uses=2]
      %lnDI = load i32* %lnDC                         ; <i32> [#uses=1]
      %lnDJ = inttoptr i32 %lnDI to void (i32*, i32*, i32*, i32)* ; <void (i32*, i32*, i32*, i32)*> [#uses=1]
      tail call cc10 void %lnDJ(i32* %Base_Arg, i32* %lnDC, i32* %Hp_Arg, i32 %lnDz) nounwind
      ret void
    }

This code looks pretty good. We see that LLVM has done many optimizations. 

1. Recursive function call is eliminated. 

2. The loop has been changed to a straight line calculation. This is possible
because all of the values are computed based on induction variables in the loop.

3. Uses of `i,j,m,s` are promoted to registers

        %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
          ...
        %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
          ...
        %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
        %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]

The only missed opportunity I see is the partially redundant loads of `s`, and
`m` in the `nDq` block. In fact, we can get LLVM to get rid of the partially
redundant loads by running a value numbering pass after `-O1`. Running 
`opt -O1 -gvn -dce` gives us this code (we can also get this code by running 
`-O2` directly):


    define cc10 void @F_zdwf_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cDh:
      %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
      %lnDn2 = icmp eq i32 %lnDl1, 0                  ; <i1> [#uses=1]
      br i1 %lnDn2, label %cDh.nDq_crit_edge, label %tailrecurse.nDq_crit_edge

    cDh.nDq_crit_edge:                                ; preds = %cDh
      %lnDs.phi.trans.insert = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=1]
      %lnDu.pre = load i32* %lnDs.phi.trans.insert    ; <i32> [#uses=1]
      %lnDw.phi.trans.insert = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=1]
      %lnDy.pre = load i32* %lnDw.phi.trans.insert    ; <i32> [#uses=1]
      br label %nDq

    tailrecurse.nDq_crit_edge:                        ; preds = %cDh
      %lnDP = getelementptr inbounds i32* %Sp_Arg, i32 1 ; <i32*> [#uses=2]
      %lnDU = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=2]
      %lnE0 = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=2]
      %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
      %tmp7 = add i32 %lnDl1, -1                      ; <i32> [#uses=2]
      %tmp8 = zext i32 %tmp7 to i33                   ; <i33> [#uses=1]
      %tmp9 = add i32 %lnDl1, -2                      ; <i32> [#uses=1]
      %tmp10 = zext i32 %tmp9 to i33                  ; <i33> [#uses=1]
      %tmp11 = mul i33 %tmp8, %tmp10                  ; <i33> [#uses=1]
      %tmp12 = lshr i33 %tmp11, 1                     ; <i33> [#uses=1]
      %tmp13 = trunc i33 %tmp12 to i32                ; <i32> [#uses=2]
      %tmp15 = mul i32 %lnDP.promoted, 5              ; <i32> [#uses=2]
      %tmp16 = add i32 %tmp15, -5                     ; <i32> [#uses=1]
      %tmp17 = mul i32 %tmp7, %tmp16                  ; <i32> [#uses=1]
      %tmp4 = mul i32 %lnDl1, %lnDl1                  ; <i32> [#uses=1]
      %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
      %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]
      %tmp20 = mul i32 %tmp13, 5                      ; <i32> [#uses=1]
      %tmp18 = add i32 %lnDU.promoted, %tmp17         ; <i32> [#uses=1]
      %tmp5 = add i32 %lnE0.promoted, %tmp4           ; <i32> [#uses=1]
      %tmp = sub i32 %lnDP.promoted, %lnDl1           ; <i32> [#uses=1]
      %tmp6 = add i32 %tmp5, 1                        ; <i32> [#uses=1]
      %tmp14 = sub i32 %tmp6, %tmp13                  ; <i32> [#uses=2]
      %tmp19 = add i32 %tmp18, %tmp15                 ; <i32> [#uses=1]
      %tmp21 = sub i32 %tmp19, %tmp20                 ; <i32> [#uses=2]
      store i32 %tmp, i32* %lnDP
      store i32 %tmp21, i32* %lnDU
      store i32 %tmp14, i32* %lnE0
      store i32 0, i32* %Sp_Arg
      br label %nDq

    nDq:                                              ; preds = %tailrecurse.nDq_crit_edge, %cDh.nDq_crit_edge
      %lnDy = phi i32 [ %lnDy.pre, %cDh.nDq_crit_edge ], [ %tmp21, %tailrecurse.nDq_crit_edge ] ; <i32> [#uses=1]
      %lnDu = phi i32 [ %lnDu.pre, %cDh.nDq_crit_edge ], [ %tmp14, %tailrecurse.nDq_crit_edge ] ; <i32> [#uses=1]
      %lnDz = add i32 %lnDy, %lnDu                    ; <i32> [#uses=1]
      %lnDC = getelementptr inbounds i32* %Sp_Arg, i32 4 ; <i32*> [#uses=2]
      %lnDI = load i32* %lnDC                         ; <i32> [#uses=1]
      %lnDJ = inttoptr i32 %lnDI to void (i32*, i32*, i32*, i32)* ; <void (i32*, i32*, i32*, i32)*> [#uses=1]
      tail call cc10 void %lnDJ(i32* %Base_Arg, i32* %lnDC, i32* %Hp_Arg, i32 %lnDz) nounwind
      ret void
    }

Now we see that loads for `s` and `m` have been inserted in the
`cDh.nDq_crit_edge` block to make the loads in the `nDq` fully redundant. The
dead code elimination pass (`dce`) has then deleted the loads in `nDq`. Now it
is up to the register allocator to decide if `s` and `m` should be kept in
real registers.

The code for `$wf` looks pretty good, but it does not yet achieve the original
goal of taking advantage of the fact the `i` and `j` are the same in the body
of `$wf` when called from `g`. In general `i` and `j` will be different in the
body of `$wf`, so if we want to take advantage of the context from `g` we will
need to inline `$wf` into the body of `g`. We saw from the `cmm` translation
of `g` that `$wf` gets called after evaluating `k` which happens in the
`spc_ret()` cmm function.

Translation of `spc_ret`
---------------------------------------------------------------------------
The LLVM code for `spc_ret` is shown below (after running it through `opt -O2`)

    define internal cc10 void @spc_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cOc:
      %lnOe = getelementptr inbounds i32* %Sp_Arg, i32 -1 ; <i32*> [#uses=1]
      store i32 0, i32* %lnOe
      %lnOg = getelementptr inbounds i32* %Sp_Arg, i32 -2 ; <i32*> [#uses=1]
      store i32 0, i32* %lnOg
      %lnOi = add i32 %R1_Arg, 3                      ; <i32> [#uses=1]
      %lnOj = inttoptr i32 %lnOi to i32*              ; <i32*> [#uses=2]
      %lnOk = load i32* %lnOj                         ; <i32> [#uses=1]
      %lnOm = getelementptr inbounds i32* %Sp_Arg, i32 -3 ; <i32*> [#uses=1]
      store i32 %lnOk, i32* %lnOm
      %lnOq = load i32* %lnOj                         ; <i32> [#uses=1]
      %lnOs = getelementptr inbounds i32* %Sp_Arg, i32 -4 ; <i32*> [#uses=2]
      store i32 %lnOq, i32* %lnOs
      store i32 ptrtoint (void (i32*, i32*, i32*, i32)* @soi_info to i32), i32* %Sp_Arg
      tail call cc10 void @F_zdwf_info(i32* %Base_Arg, i32* %lnOs, i32* %Hp_Arg, i32 %R1_Arg) nounwind
      ret void
    }

This time, the LLVM code looks a lot like the cmm code. The arguments for
`$wf` are stored on the stack and then we tail call the `$wf` function. There
is a very important sequence here that actually prevents us from getting to
the final optimization. Look at how `i` and `j` get put onto the stack.

    %lnOi = add i32 %R1_Arg, 3                          ; kA = R1 + 3
    %lnOj = inttoptr i32 %lnOi to i32*                  ; pK = (int *)kA
    %lnOk = load i32* %lnOj                             ; k1 = *pK
    %lnOm = getelementptr inbounds i32* %Sp_Arg, i32 -3 ; &j = Sp - 3
    store i32 %lnOk, i32* %lnOm                         ; *j = k1
    %lnOq = load i32* %lnOj                             ; k2 = *pK
    %lnOs = getelementptr inbounds i32* %Sp_Arg, i32 -4 ; &i = Sp - 4
    store i32 %lnOq, i32* %lnOs                         ; *i = k2

I've commented the LLVM code with the C equivalent. The interesting point here
is that LLVM loads from `pK` twice: first for `j` (`k1 = *pk`) and then again
for `i` (`k2 = *pK`). The reason it cannot eliminate the second load for `i`
is because there is an intervening store of `j` to the stack (`*j = k1`). LLVM
must assume that `&j` and `pK` alias since `pK` was an arbitrary integer that
was cast to a pointer. Thus it must reload from `pK` to get `i` after the
store to `j`.

What this means is that even if LLVM inlines the call to `$wf` in the body of
`spc_info` (which it can), the optimizer will not be able to take advantage of
the extra context because it gets tripped up by the possible alias between
`Sp` and `R1`. It will always see `i` and `j` as distinct values and will not
be able to rewrite the loop to only use `i`.

The 64-bit Story
=========================================================================== 

So far all of the code examples have been for a 32-bit system (i386). It is
instructive to see what happens when targeting a 64-bit machine (x86_64). One
major difference between the code generated by GHC for 32-bit systems and the
code for 64-bit systems is the calling convention used for function calls. On
a 32-bit system, we saw each function defined something like:

    define @F_zdwf_info(%Base_Arg, %Sp_Arg, %Hp_Arg, %R1_Arg)

With a 64-bit system we have more registers to use so the function
definitions look like:

    define @F_zdwf_info(%Base_Arg, %Sp_Arg, %Hp_Arg, %R1_Arg, 
                        %R2_Arg, %R3_Arg, %R4_Arg, %R5_Arg, %R6_Arg, 
                        %SpLim_Arg,
                        %F1_Arg, %F2_Arg, %F3_Arg, %F4_Arg,
                        %D1_Arg, %D2_Arg)

The GHC calling convention for x86_64 passes the same 4 registers as i386
(`Base, Sp, Hp, R1`), plus an additional 5 registers for function arguments
(`R2` - `R6`), the stack limit `SpLim`, 4 float (`F1` - `F4`), and two
double (`D1`, `D2`) parameters.

Now if we look at the cmm for the `$wf` loop, we see that the 4 parameters are
passed in registers.

    F.$wf_entry()
        cqB:
            _sn2::I64 = R2;
            if (_sn2::I64 != 0) goto cqF;
            _cqJ::I64 = R4 + R5;
            R1 = _cqJ::I64;
            jump (I64[Sp + 0]) ();
        cqF:
            _sop::I64 = R3 * 5;
            _sok::I64 = R5 + _sop::I64;
            _soo::I64 = R4 + _sn2::I64;
            _son::I64 = _soo::I64 + 1;
            _som::I64 = R3 - 1;
            _sol::I64 = _sn2::I64 - 1;
            R2 = _sol::I64;
            R3 = _som::I64;
            R4 = _son::I64;
            R5 = _sok::I64;
            jump F.$wf_info ();
    }

LLVM does a good job at optimizing this loop as above. It removes the
recursion and then changes the loop into straight line code based on the
induction variables.

More importantly, if we look at the call site for `$wf` it looks much improved:

    define internal cc10 void @soI_info(i64* noalias nocapture %Base_Arg, i64* noalias nocapture %Sp_Arg, i64* noalias nocapture %Hp_Arg, i64 %R1_Arg, i64 %R2_Arg, i64 %R3_Arg, i64 %R4_Arg, i64 %R5_Arg, i64 %R6_Arg, i64 %SpLim_Arg, float %F1_Arg, float %F2_Arg, float %F3_Arg, float %F4_Arg, double %D1_Arg, double %D2_Arg) nounwind section ".text; .text 1#" align 8 {
    cHS:
      %lnHU = add i64 %R1_Arg, 7                      ; <i64> [#uses=1]
      %lnHV = inttoptr i64 %lnHU to i64*              ; <i64*> [#uses=1]
      %lnHW = load i64* %lnHV                         ; <i64> [#uses=2]
      store i64 ptrtoint (void (i64*, i64*, i64*, i64, i64, i64, i64, i64, i64, i64, float, float, float, float, double, double)* @snE_info to i64), i64* %Sp_Arg
      tail call cc10 void @F_zdwf_info(i64* %Base_Arg, i64* %Sp_Arg, i64* %Hp_Arg, i64 %R1_Arg, i64 %lnHW, i64 %lnHW, i64 0, i64 0, i64 %R6_Arg, i64 %SpLim_Arg, float %F1_Arg, float %F2_Arg, float %F3_Arg, float %F4_Arg, double %D1_Arg, double %D2_Arg) nounwind
      ret void
    }

Since parameters are passed in registers, there is no problem with aliasing
between `Sp` and `R1`. The `k` value is loaded once from `R1` and then passed
to `$fw` in the `R2` and `R3` register spots.

Now if we get LLVM to inline the `$fw` function at this call site it should be
able to take advantage of the extra context and just use `i` in the body of
the "loop". Running `opt -O2 -inline -std-compile-opts` give us this code:

    define internal cc10 void @soI_info(i64* noalias nocapture %Base_Arg, i64* noalias nocapture %Sp_Arg, i64* noalias nocapture %Hp_Arg, i64 %R1_Arg, i64 %R2_Arg, i64 %R3_Arg, i64 %R4_Arg, i64 %R5_Arg, i64 %R6_Arg, i64 %SpLim_Arg, float %F1_Arg, float %F2_Arg, float %F3_Arg, float %F4_Arg, double %D1_Arg, double %D2_Arg) nounwind section ".text; .text 1#" align 8 {
    cHS:
      %lnHU = add i64 %R1_Arg, 7                      ; <i64> [#uses=1]
      %lnHV = inttoptr i64 %lnHU to i64*              ; <i64*> [#uses=1]
      %lnHW = load i64* %lnHV                         ; <i64> [#uses=7]
      store i64 ptrtoint (void (i64*, i64*, i64*, i64, i64, i64, i64, i64, i64, i64, float, float, float, float, double, double)* @snE_info to i64), i64* %Sp_Arg
      %lnrL1.i = icmp eq i64 %lnHW, 0                 ; <i1> [#uses=1]
      br i1 %lnrL1.i, label %F_zdwf_info.exit, label %bb.nph.i

    bb.nph.i:                                         ; preds = %cHS
      %tmp12.i = add i64 %lnHW, -1                    ; <i64> [#uses=2]
      %tmp13.i = zext i64 %tmp12.i to i65             ; <i65> [#uses=1]
      %tmp14.i = add i64 %lnHW, -2                    ; <i64> [#uses=1]
      %tmp15.i = zext i64 %tmp14.i to i65             ; <i65> [#uses=1]
      %tmp16.i = mul i65 %tmp13.i, %tmp15.i           ; <i65> [#uses=1]
      %tmp17.i = lshr i65 %tmp16.i, 1                 ; <i65> [#uses=1]
      %tmp18.i = trunc i65 %tmp17.i to i64            ; <i64> [#uses=2]
      %tmp20.i = mul i64 %lnHW, 5                     ; <i64> [#uses=2]
      %tmp21.i = add i64 %tmp20.i, -5                 ; <i64> [#uses=1]
      %tmp22.i = mul i64 %tmp21.i, %tmp12.i           ; <i64> [#uses=1]
      %tmp9.i = mul i64 %lnHW, %lnHW                  ; <i64> [#uses=1]
      %tmp25.i = mul i64 %tmp18.i, 5                  ; <i64> [#uses=1]
      %tmp11.i = add i64 %tmp9.i, 1                   ; <i64> [#uses=1]
      %tmp19.i = sub i64 %tmp11.i, %tmp18.i           ; <i64> [#uses=1]
      %tmp24.i = add i64 %tmp22.i, %tmp20.i           ; <i64> [#uses=1]
      %tmp26.i = sub i64 %tmp24.i, %tmp25.i           ; <i64> [#uses=1]
      br label %F_zdwf_info.exit
      ...

Here we finally have accomplished what we set out to do. This code can see the
equivalence of `i` and `j` and only uses `i` (`%lnHW`) in the body of the
"loop".

Conclusion
===========================================================================

In this article we explored the optimization of Haskell loops using LLVM.
Haskell loops are represented as tail recursive functions. We saw that LLVM is
able to change a tail recursive function into an actual loop and then apply
some loop optimizations. In particular, we saw that LLVM can turn a loop where
all calculations are done with induction variables into a piece of straight
line code that directly computes the result of the loop.

The original question was whether LLVM could transform a loop of two induction
variables into a loop with just one. We saw that for x86_64, this
transformation is possible, but that for i386, the possible aliasing between
the stack pointer and the function argument pointer prevented this
transformation.

Exploring the details of the code generation for Haskell loops was a useful
exercise. We found several sources of problems for optimizing the generated
code.

1. The ability of LLVM to optimize Haskell functions is limited by the calling
convention. Particularly for i386, function arguments are passed on a stack
that LLVM knows nothing about. The reads and writes to the stack look like
arbitrary loads and stores. It has no notion of popping elements from the
stack which makes it difficult to know when it is ok to eliminate stores to
the stack. 

2. The possible aliasing introduced by casting integer arguments
(R1-R6) to pointers limits the effectiveness of its optimizations.

3. A single Haskell source function is broken up into many small functions in
the back end. Every evaluation of a case statement requires a new continuation
point. These small functions kill the optimization context for LLVM. LLVM can
recover some of the context by inlining calls to known functions, but the
effectiveness of inlining is limited since it does not know that we are
passing some parameters on the stack and not through the actual function call.

4. The order of optimizations matter. We saw that just running `-O2` on the
code may not be enough to get the full optimization effects. To get the full
benefits of inlining in the x86_64 backend, we had to use the heavyweight
sequence `-O2 -inline -std-compiler-opts`.

I am interested in exploring several different opportunities.

* Make the cmm more friendly to LLVM by inlining and making loops in cmm

    I think LLVM would benefit a lot from having a larger optimization
    context. We could relieve some of the burden on LLVM by doing some
    inlining and eliminating tail calls in the cmm itself. GHC knows that it
    is passing arguments on the stack, so it should be able to inline and turn
    tail calls into loops much better than LLVM can.

*  Different calling conventions

    All the functions in the code generated for LLVM use the same calling
    convention fixed by GHC. It would be interesting to see if we could
    generate LLVM code where we pass all the arguments a function needs as
    actual arguments. We can then let LLVM do its optimizations and then have
    a later pass that spills extra arguments to the stack and makes our
    functions use the correct GHC calling convention.

*  Specialization of code after a runtime alias check

    We could specialize the code into two cases, one where some pointers may
    alias and one where they do not. We can then let LLVM fully optimized the
    code with no aliases. We would insert a check at runtime to see if there
    are aliases and then call the correct bit of code.

*  Optimization order matters

    Probably there are some wins to be had by choosing a good optimization
    sequence for the code generated from GHC, rather than just using `-O1`,
    `-O2`, etc. I believe It should be possible to find a good optimization
    sequence that would work well for Haskell codes.


[1]: http://www.haskell.org/pipermail/glasgow-haskell-users/2010-November/019446.html
[2]: http://hackage.haskell.org/trac/ghc/wiki/Commentary/Compiler/GeneratedCode (The GHC Commentary)
[3]: http://dx.doi.org/10.1016/S0167-6423(97)00029-4 (A transformation-based optimiser for Haskell, Section 6.2)