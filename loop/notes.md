Introduction
===========================================================================
The question was asked whether we could change the function `f` with the call
site g:

    f :: Int -> Int -> Int -> Int -> Int
    f !i !j !s !m
     | i == 0    = s+m
     | otherwise = f (i-1) (j-1) (s + i+1) (m + j*5)

     g :: Int -> Int
     g !k = f k k 0 0

into the function `ff` with call site `gg`:

    ff :: Int -> Int -> Int -> Int
    ff !i !s !m
     | i == 0    = s+m
     | otherwise = ff (i-1) (s + i+1) (m + i*5)

    gg :: Int -> Int
    gg !k = ff k 0 0

Basically, we wanted to do some kind of value numbering to replace the j
references with i, since i and j are equal throughout the loop. It was
suggested that this transformation would help code generated by stream fusion
transformation.

It is possible to get LLVM to do this transformation through a combination of
tail-call elimination, inlining, induction variable optimization, and global
value numbering. This works fine on x86_64 where we can pass parameters in
registers, but fails to fully fire in i386 back end because LLVM gets caught
up by aliasing problems because all function parameters are passed on the
stack.

The Power of LLVM
===========================================================================

LLVM does a great job of optimizing the loops it can see. If we translate the
`f` function to a simple loop in C we would get something like this:

    fWorker(int i, int j, int s, int m) {
      loop:
        if(i == 0) goto end;
        s = s + i + 1;
        m = m + j * 5;
        i = i - 1;
        j = j - 1;
        goto loop;
      end:
        return s + m;
    }

    g(int k) {
      return fWorker(k,k,0,0);
    }

Running `opt -mem2reg -inline -indvars -loop-deletion` on the LLVM bitcode, we
get the following output.

    define i32 @g(i32 %k) nounwind ssp {
    entry:
      %"alloca point" = bitcast i32 0 to i32          ; <i32> [#uses=0]
      %tmp.i = add i32 %k, 1                          ; <i32> [#uses=1]
      %tmp1.i = mul i32 %k, %tmp.i                    ; <i32> [#uses=1]
      %tmp3.i = zext i32 %k to i33                    ; <i33> [#uses=1]
      %tmp4.i = add i32 %k, -1                        ; <i32> [#uses=1]
      %tmp5.i = zext i32 %tmp4.i to i33               ; <i33> [#uses=1]
      %tmp6.i = mul i33 %tmp3.i, %tmp5.i              ; <i33> [#uses=1]
      %tmp7.i = lshr i33 %tmp6.i, 1                   ; <i33> [#uses=1]
      %tmp8.i = trunc i33 %tmp7.i to i32              ; <i32> [#uses=2]
      %tmp10.i = mul i32 %k, %k                       ; <i32> [#uses=1]
      %tmp11.i = mul i32 %tmp10.i, 5                  ; <i32> [#uses=1]
      %tmp13.i = mul i32 %tmp8.i, 5                   ; <i32> [#uses=1]
      %tmp2.i = add i32 0, %tmp1.i                    ; <i32> [#uses=1]
      %tmp9.i = sub i32 %tmp2.i, %tmp8.i              ; <i32> [#uses=1]
      %tmp12.i = add i32 0, %tmp11.i                  ; <i32> [#uses=1]
      %tmp14.i = sub i32 %tmp12.i, %tmp13.i           ; <i32> [#uses=1]
      %0 = add nsw i32 %tmp9.i, %tmp14.i              ; <i32> [#uses=1]
      br label %return

    return:                                           ; preds = %entry
      ret i32 %0
    }

We see that the `fWorker` function was inlined into the body of `g`. LLVM was
also able to transform the loop into a simple calculation since all the loop
does is some computation based on induction variables. Also, we see that the
variable `%k` takes the place of both `i` and `j` in the original loop, which
accomplishes the original goal: `g` has been transformed into an *optimized*
version of `gg`.

If we can translate the original Haskell function `f` into something that
looks like our C loop, we can be confident that LLVM will do a good job
optimizing it.

Haskell Loops
===========================================================================

GHC does a worker/wrapper transformation on the function `f` which produces
the following worker function:

    F.$wf =
      \ (ww_smi :: GHC.Prim.Int#)
        (ww1_smm :: GHC.Prim.Int#)
        (ww2_smq :: GHC.Prim.Int#)
        (ww3_smu :: GHC.Prim.Int#) ->
        case ww_smi of wild_B1 {
          __DEFAULT ->
            F.$wf
              (GHC.Prim.-# wild_B1 1)
              (GHC.Prim.-# ww1_smm 1)
              (GHC.Prim.+# (GHC.Prim.+# ww2_smq wild_B1) 1)
              (GHC.Prim.+# ww3_smu (GHC.Prim.*# ww1_smm 5));
          0 -> GHC.Prim.+# ww2_smq ww3_smu
        }

The function `g` first evaluates the `k` parameter that was passed to it then
calls the worker function (`$wf`) directly from `g`. Note that GHC can not
inline the worker function here because it is a recursive function.

    F.g =
      \ (k_ag4 :: GHC.Types.Int) ->
        case k_ag4 of _ { GHC.Types.I# ww_smi ->
        case F.$wf ww_smi ww_smi 0 0 of ww1_smy { __DEFAULT ->
        GHC.Types.I# ww1_smy
        }
        }
        
When `g` gets lowered to cmm, it is broken into three pieces: 

1. Entry to the function `g`
2. The return from the first case (after evaluating the parameter `k`)
3. The return from the second case (after the `$wf` function)

Entry to `g`
---------------------------------------------------------------------------
    F.g_entry()
        cOF:
            if (Sp - 16 < I32[BaseReg + 84]) goto cOH;
            R1 = I32[Sp + 0];
            I32[Sp + 0] = spc_info;
            if (R1 & 3 != 0) goto cOK;
            jump I32[R1] ();
        cOH:
            R1 = F.g_closure;
            jump (I32[BaseReg - 4]) ();
        cOK: jump spc_info ();


The entry to the `g` function is pretty straight forward. It first does a
stack check to make sure it has enough room to call `$wf` (16 bytes are
required for the 4 parameters). Next it loads `k` into `R1` and pushes the
return address `spc_info` onto the stack. It checks the tag bits on `k`
(stored in `R1`) to see if it is already evaluated and either jumps to it to
evaluate it or jumps directly to the continuation (`spc_info`).

The return from evaluating `k` is handled in the `spc_info` function.


Return from the first case (evaluating the parameter `k`)
---------------------------------------------------------------------------
    spc_ret()
        cNL:
            I32[Sp - 4] = 0;
            I32[Sp - 8] = 0;
            I32[Sp - 12] = I32[R1 + 3];
            I32[Sp - 16] = I32[R1 + 3];
            I32[Sp + 0] = soi_info;
            Sp = Sp - 16;
            jump F.$wf_info ();
            
On entry to the `spc_ret` function, we know that `k` is evaluated and stored
in `R1`. The `spc_ret` function pushes the return address (`soi_info`) and all
of the arguments for the `$wf` function onto the stack and then calls the
`$wf` function.

Remember that `k` is a boxed integer, so `R1` points to a heap allocated chunk
8 bytes long that contains the `I#` tag in the first word and the primitive
integer in the second word. `R1` is tagged as evaluated on entry to `spc_ret`
which means that the lowest bit is already set to one. To get to the the
primitive int, we need to move over three more bytes which is why we see the
load of [R1 + 3].

Once all the parameters are on the stack, we call the `$wf` function.

The Loop (`$wf` function)
---------------------------------------------------------------------------
    F.$wf_entry()
    cC1:
        _snG::I32 = I32[Sp + 0];
        if (_snG::I32 != 0) goto cC5;
        _cC9::I32 = I32[Sp + 8] + I32[Sp + 12];
        R1 = _cC9::I32;
        Sp = Sp + 16;
        jump (I32[Sp + 0]) ();
    cC5:
        _soT::I32 = I32[Sp + 4] * 5;
        _soO::I32 = I32[Sp + 12] + _soT::I32;
        _soS::I32 = I32[Sp + 8] + _snG::I32;
        _soR::I32 = _soS::I32 + 1;
        _soQ::I32 = I32[Sp + 4] - 1;
        _soP::I32 = _snG::I32 - 1;
        I32[Sp + 12] = _soO::I32;
        I32[Sp + 8] = _soR::I32;
        I32[Sp + 4] = _soQ::I32;
        I32[Sp + 0] = _soP::I32;
        jump F.$wf_info ();

The `$wf` function is compiled to something that looks quite a bit like a
loop. On entry to `$wf`, the stack looks as follows (stack grows down):

          -----------
          |soi_info|
          ----------
          |   m    |
          ----------
          |   s    |
          ----------
          |   j    |
    Sp -> ----------
          |   i    |
          ----------

We check to see if the loop should end (`i == 0`) and if so we load the return
value into `R1`, pop the arguments from the stack and jump to the return
address. The main body of the loop computes the updates to the parameters,
stores them back onto the stack, and jumps back to the top of the function.


Return from the second case (the `$wf` function)
---------------------------------------------------------------------------
    soi_ret()
        cMk:
            Hp = Hp + 8;
            if (Hp > I32[BaseReg + 92]) goto cMq;
            I32[Hp - 4] = GHC.Types.I#_con_info;
            I32[Hp + 0] = R1;
            R1 = Hp - 3;
            Sp = Sp + 4;
            jump (I32[Sp + 0]) ();
        cMr: jump stg_gc_unbx_r1 ();
        cMq:
            I32[BaseReg + 112] = 8;
            goto cMr;

After returning from `$wf` we need to box the primitive integer (returned to
us from `$wf` in `R1`) and jump to the return address on top of the stack. We
box the int by allocating 8 bytes in the heap and storing the `I#` tag and the
primitive int in our freshly allocated space. Next, The `k` value that was
passed to `g` is then popped from the stack (`Sp = Sp + 4`). Finally, we jump
to the return address on top of the stack that contains the continuation for
`g`.

Translation to LLVM
===========================================================================
Now let's take a look at how the `$wf` gets translated into LLVM bitcode. In
particular, we will take a look at the LLVM translation of the `F.$wf_entry()`
and `spc_ret()` cmm functions.

Translation of `$wf`
---------------------------------------------------------------------------
After translating to LLVM, we run `opt -O1` and get the following LLVM code:

    define cc10 void @F_zdwf_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cDh:
      %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
      %lnDn2 = icmp eq i32 %lnDl1, 0                  ; <i1> [#uses=1]
      br i1 %lnDn2, label %nDq, label %tailrecurse.nDq_crit_edge

    tailrecurse.nDq_crit_edge:                        ; preds = %cDh
      %lnDP = getelementptr inbounds i32* %Sp_Arg, i32 1 ; <i32*> [#uses=2]
      %lnDU = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=2]
      %lnE0 = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=2]
      %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
      %tmp7 = add i32 %lnDl1, -1                      ; <i32> [#uses=2]
      %tmp8 = zext i32 %tmp7 to i33                   ; <i33> [#uses=1]
      %tmp9 = add i32 %lnDl1, -2                      ; <i32> [#uses=1]
      %tmp10 = zext i32 %tmp9 to i33                  ; <i33> [#uses=1]
      %tmp11 = mul i33 %tmp8, %tmp10                  ; <i33> [#uses=1]
      %tmp12 = lshr i33 %tmp11, 1                     ; <i33> [#uses=1]
      %tmp13 = trunc i33 %tmp12 to i32                ; <i32> [#uses=2]
      %tmp15 = mul i32 %lnDP.promoted, 5              ; <i32> [#uses=2]
      %tmp16 = add i32 %tmp15, -5                     ; <i32> [#uses=1]
      %tmp17 = mul i32 %tmp7, %tmp16                  ; <i32> [#uses=1]
      %tmp4 = mul i32 %lnDl1, %lnDl1                  ; <i32> [#uses=1]
      %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
      %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]
      %tmp20 = mul i32 %tmp13, 5                      ; <i32> [#uses=1]
      %tmp18 = add i32 %lnDU.promoted, %tmp17         ; <i32> [#uses=1]
      %tmp5 = add i32 %lnE0.promoted, %tmp4           ; <i32> [#uses=1]
      %tmp = sub i32 %lnDP.promoted, %lnDl1           ; <i32> [#uses=1]
      %tmp6 = add i32 %tmp5, 1                        ; <i32> [#uses=1]
      %tmp14 = sub i32 %tmp6, %tmp13                  ; <i32> [#uses=1]
      %tmp19 = add i32 %tmp18, %tmp15                 ; <i32> [#uses=1]
      %tmp21 = sub i32 %tmp19, %tmp20                 ; <i32> [#uses=1]
      store i32 %tmp, i32* %lnDP
      store i32 %tmp21, i32* %lnDU
      store i32 %tmp14, i32* %lnE0
      store i32 0, i32* %Sp_Arg
      br label %nDq

    nDq:                                              ; preds = %tailrecurse.nDq_crit_edge, %cDh
      %lnDs = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=1]
      %lnDu = load i32* %lnDs                         ; <i32> [#uses=1]
      %lnDw = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=1]
      %lnDy = load i32* %lnDw                         ; <i32> [#uses=1]
      %lnDz = add i32 %lnDy, %lnDu                    ; <i32> [#uses=1]
      %lnDC = getelementptr inbounds i32* %Sp_Arg, i32 4 ; <i32*> [#uses=2]
      %lnDI = load i32* %lnDC                         ; <i32> [#uses=1]
      %lnDJ = inttoptr i32 %lnDI to void (i32*, i32*, i32*, i32)* ; <void (i32*, i32*, i32*, i32)*> [#uses=1]
      tail call cc10 void %lnDJ(i32* %Base_Arg, i32* %lnDC, i32* %Hp_Arg, i32 %lnDz) nounwind
      ret void
    }

This code looks pretty good. We see that LLVM has done many optimizations. 

1. Recursive function call is eliminated. 

2. The loop has been changed to a straight line calculation. This is possible
because all of the values are computed based on induction variables in the loop.

3. Uses of `i,j,m,s` are promoted to registers

        %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
          ...
        %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
          ...
        %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
        %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]

The only missed opportunity I see is the partially redundant loads of `s`, and
`m` in the `nDq` block. In fact, we can get LLVM to get rid of the partially
redundant loads by running a value numbering pass after `-O1`. Running `opt -O1
-gvn -dce` gives us this code (we can also get this code by running `-O2`
directly):


    define cc10 void @F_zdwf_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cDh:
      %lnDl1 = load i32* %Sp_Arg                      ; <i32> [#uses=6]
      %lnDn2 = icmp eq i32 %lnDl1, 0                  ; <i1> [#uses=1]
      br i1 %lnDn2, label %cDh.nDq_crit_edge, label %tailrecurse.nDq_crit_edge

    cDh.nDq_crit_edge:                                ; preds = %cDh
      %lnDs.phi.trans.insert = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=1]
      %lnDu.pre = load i32* %lnDs.phi.trans.insert    ; <i32> [#uses=1]
      %lnDw.phi.trans.insert = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=1]
      %lnDy.pre = load i32* %lnDw.phi.trans.insert    ; <i32> [#uses=1]
      br label %nDq

    tailrecurse.nDq_crit_edge:                        ; preds = %cDh
      %lnDP = getelementptr inbounds i32* %Sp_Arg, i32 1 ; <i32*> [#uses=2]
      %lnDU = getelementptr inbounds i32* %Sp_Arg, i32 3 ; <i32*> [#uses=2]
      %lnE0 = getelementptr inbounds i32* %Sp_Arg, i32 2 ; <i32*> [#uses=2]
      %lnDP.promoted = load i32* %lnDP                ; <i32> [#uses=2]
      %tmp7 = add i32 %lnDl1, -1                      ; <i32> [#uses=2]
      %tmp8 = zext i32 %tmp7 to i33                   ; <i33> [#uses=1]
      %tmp9 = add i32 %lnDl1, -2                      ; <i32> [#uses=1]
      %tmp10 = zext i32 %tmp9 to i33                  ; <i33> [#uses=1]
      %tmp11 = mul i33 %tmp8, %tmp10                  ; <i33> [#uses=1]
      %tmp12 = lshr i33 %tmp11, 1                     ; <i33> [#uses=1]
      %tmp13 = trunc i33 %tmp12 to i32                ; <i32> [#uses=2]
      %tmp15 = mul i32 %lnDP.promoted, 5              ; <i32> [#uses=2]
      %tmp16 = add i32 %tmp15, -5                     ; <i32> [#uses=1]
      %tmp17 = mul i32 %tmp7, %tmp16                  ; <i32> [#uses=1]
      %tmp4 = mul i32 %lnDl1, %lnDl1                  ; <i32> [#uses=1]
      %lnE0.promoted = load i32* %lnE0                ; <i32> [#uses=1]
      %lnDU.promoted = load i32* %lnDU                ; <i32> [#uses=1]
      %tmp20 = mul i32 %tmp13, 5                      ; <i32> [#uses=1]
      %tmp18 = add i32 %lnDU.promoted, %tmp17         ; <i32> [#uses=1]
      %tmp5 = add i32 %lnE0.promoted, %tmp4           ; <i32> [#uses=1]
      %tmp = sub i32 %lnDP.promoted, %lnDl1           ; <i32> [#uses=1]
      %tmp6 = add i32 %tmp5, 1                        ; <i32> [#uses=1]
      %tmp14 = sub i32 %tmp6, %tmp13                  ; <i32> [#uses=2]
      %tmp19 = add i32 %tmp18, %tmp15                 ; <i32> [#uses=1]
      %tmp21 = sub i32 %tmp19, %tmp20                 ; <i32> [#uses=2]
      store i32 %tmp, i32* %lnDP
      store i32 %tmp21, i32* %lnDU
      store i32 %tmp14, i32* %lnE0
      store i32 0, i32* %Sp_Arg
      br label %nDq

    nDq:                                              ; preds = %tailrecurse.nDq_crit_edge, %cDh.nDq_crit_edge
      %lnDy = phi i32 [ %lnDy.pre, %cDh.nDq_crit_edge ], [ %tmp21, %tailrecurse.nDq_crit_edge ] ; <i32> [#uses=1]
      %lnDu = phi i32 [ %lnDu.pre, %cDh.nDq_crit_edge ], [ %tmp14, %tailrecurse.nDq_crit_edge ] ; <i32> [#uses=1]
      %lnDz = add i32 %lnDy, %lnDu                    ; <i32> [#uses=1]
      %lnDC = getelementptr inbounds i32* %Sp_Arg, i32 4 ; <i32*> [#uses=2]
      %lnDI = load i32* %lnDC                         ; <i32> [#uses=1]
      %lnDJ = inttoptr i32 %lnDI to void (i32*, i32*, i32*, i32)* ; <void (i32*, i32*, i32*, i32)*> [#uses=1]
      tail call cc10 void %lnDJ(i32* %Base_Arg, i32* %lnDC, i32* %Hp_Arg, i32 %lnDz) nounwind
      ret void
    }

Now we see that loads for `s` and `m` have been inserted in the
`cDh.nDq_crit_edge` block to make the loads in the `nDq` fully redundant. The
dead code elimination pass (`dce`) has then deleted the loads in `nDq`. Now it
is up to the register allocator to decide if `s` and `m` should be kept in
real registers.

The code for `$wf` looks pretty good, but it does not yet achieve the original
goal of taking advantage of the fact the `i` and `j` are the same in the body
of `$wf` when called from `g`. In general `i` and `j` will be different in the
body of `$wf`, so if we want to take advantage of the context from `g` we will
need to inline `$wf` into the body of `g`. We saw from the `cmm` translation
of `g` that `$wf` gets called after evaluating `k` which happens in the
`spc_ret()` cmm function.

Translation of `spc_ret`
---------------------------------------------------------------------------
The LLVM code for `spc_ret` is shown below (after running it through `opt -O2`)

    define internal cc10 void @spc_info(i32* noalias nocapture %Base_Arg, i32* noalias nocapture %Sp_Arg, i32* noalias nocapture %Hp_Arg, i32 %R1_Arg) nounwind section "__STRIP,__me1" align 4 {
    cOc:
      %lnOe = getelementptr inbounds i32* %Sp_Arg, i32 -1 ; <i32*> [#uses=1]
      store i32 0, i32* %lnOe
      %lnOg = getelementptr inbounds i32* %Sp_Arg, i32 -2 ; <i32*> [#uses=1]
      store i32 0, i32* %lnOg
      %lnOi = add i32 %R1_Arg, 3                      ; <i32> [#uses=1]
      %lnOj = inttoptr i32 %lnOi to i32*              ; <i32*> [#uses=2]
      %lnOk = load i32* %lnOj                         ; <i32> [#uses=1]
      %lnOm = getelementptr inbounds i32* %Sp_Arg, i32 -3 ; <i32*> [#uses=1]
      store i32 %lnOk, i32* %lnOm
      %lnOq = load i32* %lnOj                         ; <i32> [#uses=1]
      %lnOs = getelementptr inbounds i32* %Sp_Arg, i32 -4 ; <i32*> [#uses=2]
      store i32 %lnOq, i32* %lnOs
      store i32 ptrtoint (void (i32*, i32*, i32*, i32)* @soi_info to i32), i32* %Sp_Arg
      tail call cc10 void @F_zdwf_info(i32* %Base_Arg, i32* %lnOs, i32* %Hp_Arg, i32 %R1_Arg) nounwind
      ret void
    }

This time, the LLVM code looks a lot like the cmm code. The arguments for
`$wf` are stored on the stack and then we tail call the `$wf` function. There
is a very important sequence here that actually prevents us from getting to
the final optimization. Look at how `i` and `j` get put onto the stack.

    %lnOi = add i32 %R1_Arg, 3                          ; kA = R1 + 3
    %lnOj = inttoptr i32 %lnOi to i32*                  ; pK = (int *)kA
    %lnOk = load i32* %lnOj                             ; k1 = *pK
    %lnOm = getelementptr inbounds i32* %Sp_Arg, i32 -3 ; &j = Sp - 3
    store i32 %lnOk, i32* %lnOm                         ; *j = k1
    %lnOq = load i32* %lnOj                             ; k2 = *pK
    %lnOs = getelementptr inbounds i32* %Sp_Arg, i32 -4 ; &i = Sp - 4
    store i32 %lnOq, i32* %lnOs                         ; *i = k2

I've commented the LLVM code with the C equivalent. The interesting point here
is that LLVM loads from `pK` twice: first for `j` (`k1 = *pk`) and then again
for `i` (`k2 = *pK`). The reason it cannot eliminate the second load for `i`
is because there is an intervening store of `j` to the stack (`*j = k1`). LLVM
must assume that `&j` and `pK` alias since `pK` was an arbitrary integer that
was cast to a pointer. Thus it must reload from `pK` to get `i` after the
store to `j`.

What this means is that even if LLVM inlines the call to `$wf` in the body of
`spc_info` (which it can), the optimizer will not be able to take advantage of
the extra context because it gets tripped up by the possible alias between
`Sp` and `R1`. It will always see `i` and `j` as distinct values and will not
be able to rewrite the loop to only use `i`.

The 64-bit Story
=========================================================================== So
far all of the code examples have been for a 32-bit system. It is instructive
to see what happens when targeting a 64-bit machine.


Conclusion
===========================================================================

[Problem] Function calls pass data on the stack that llvm does not know about
which causes it to not properly inline the function call.

[Problem] Smaller functions gives less context for optimization. More context
can be had by inlining, but this is made more difficult by the explicit stack
manipulation.

[Problem] Maintaining a separate stack that is used to pass parameters makes
it harder for llvm to inline.

[Suggestion] Make the loops and do inlining in cmm






